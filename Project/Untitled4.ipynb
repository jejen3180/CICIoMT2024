{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0174f62-728f-4cd6-a2ea-1613bf186de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrastive Learning + Zero-Day Detection for IoMT IDS (Triplet Loss for Better Embedding)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from scipy.spatial import distance\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed80f6f-ad83-4b18-bdc1-8f5428e31077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Dataset ===\n",
    "def load_dataset_from_structure(root_path):\n",
    "    data = []\n",
    "    for file in root_path.glob(\"**/*.csv\"):\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            if df.empty: continue\n",
    "            category = file.parent.parent.name\n",
    "            attack = file.parent.name\n",
    "            label_class = 'Benign' if category.upper() == 'BENIGN' else 'Attack'\n",
    "            df['category'] = category\n",
    "            df['attack'] = attack\n",
    "            df['class'] = label_class\n",
    "            data.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to read file {file}: {e}\")\n",
    "    return pd.concat(data, ignore_index=True) if data else pd.DataFrame()\n",
    "\n",
    "train_root = Path('../../../Data/CICIoMT2024/train')\n",
    "test_root = Path('../../../Data/CICIoMT2024/test')\n",
    "\n",
    "train_df = load_dataset_from_structure(train_root)\n",
    "test_df = load_dataset_from_structure(test_root)\n",
    "\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66e8c09-6401-444b-a26b-6aff57f26e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Triplet Loss Function ===\n",
    "def triplet_loss(margin=1.0):\n",
    "    def loss(y_true, y_pred):\n",
    "        anchor, positive, negative = y_pred[:, :32], y_pred[:, 32:64], y_pred[:, 64:]\n",
    "        pos_dist = K.sum(K.square(anchor - positive), axis=1)\n",
    "        neg_dist = K.sum(K.square(anchor - negative), axis=1)\n",
    "        return K.mean(K.maximum(pos_dist - neg_dist + margin, 0.0))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabd75ad-601a-4adc-9371-080b97940714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Unique attack values: ['BENIGN' 'DDOS ICMP' 'DDOS SYN' 'DDOS TCP' 'DDOS UDP' 'DOS ICMP'\n",
      " 'DOS SYN' 'DOS TCP' 'DOS UDP' 'DDOS CONNECT FLOOD' 'DDOS PUBLISH FLOOD'\n",
      " 'DOS CONNECT FLOOD' 'DOS PUBLISH FLOOD' 'MALFORMED DATA' 'OS SCAN'\n",
      " 'PING SWEEP' 'PORT SCAN' 'RECON VULSCAN' 'SPOOFING']\n",
      "[INFO] valid_cols: 45 features\n",
      "[INFO] triplet_benign shape: (17791, 45)\n",
      "[INFO] triplet_attack shape: (17791, 45)\n",
      "[INFO] triplet_zero shape: (17791, 45)\n"
     ]
    }
   ],
   "source": [
    "# === Prepare Data ===\n",
    "df['attack'] = df['attack'].str.upper().str.strip()\n",
    "df['class'] = df['class'].str.upper().str.strip()\n",
    "\n",
    "print(\"ğŸ” Unique attack values:\", df['attack'].unique())\n",
    "\n",
    "zero_attack_label = 'SPOOFING'  # Fokus zero-day spoofing\n",
    "benign_df = df[df['class'] == 'BENIGN'].copy()\n",
    "zero_df = df[df['attack'] == zero_attack_label].copy()\n",
    "attack_df = df[(df['class'] == 'ATTACK') & (df['attack'] != zero_attack_label)].copy()\n",
    "\n",
    "triplet_size = min(len(benign_df), len(zero_df), len(attack_df))\n",
    "if triplet_size == 0:\n",
    "    raise ValueError(\"Triplet datasets are empty. Periksa kembali label 'BENIGN', 'SPOOFING', atau struktur data.\")\n",
    "\n",
    "triplet_benign = benign_df.sample(n=triplet_size, random_state=42)\n",
    "triplet_attack = attack_df.sample(n=triplet_size, random_state=42)\n",
    "triplet_zero = zero_df.sample(n=triplet_size, random_state=42)\n",
    "\n",
    "feature_cols = df.select_dtypes(include='number').columns.tolist()\n",
    "triplet_benign = triplet_benign.dropna(subset=feature_cols)\n",
    "triplet_attack = triplet_attack.dropna(subset=feature_cols)\n",
    "triplet_zero = triplet_zero.dropna(subset=feature_cols)\n",
    "\n",
    "valid_cols = list(set(feature_cols).intersection(\n",
    "    triplet_benign.columns, triplet_attack.columns, triplet_zero.columns\n",
    "))\n",
    "\n",
    "print(f\"[INFO] valid_cols: {len(valid_cols)} features\")\n",
    "print(f\"[INFO] triplet_benign shape: {triplet_benign[valid_cols].shape}\")\n",
    "print(f\"[INFO] triplet_attack shape: {triplet_attack[valid_cols].shape}\")\n",
    "print(f\"[INFO] triplet_zero shape: {triplet_zero[valid_cols].shape}\")\n",
    "\n",
    "if not valid_cols:\n",
    "    raise ValueError(\"Tidak ada fitur numerik yang cocok di antara triplet datasets. Periksa kembali struktur datanya.\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[valid_cols])\n",
    "\n",
    "anchor = scaler.transform(triplet_benign[valid_cols])\n",
    "positive = scaler.transform(triplet_attack[valid_cols])\n",
    "negative = scaler.transform(triplet_zero[valid_cols])\n",
    "\n",
    "X_triplet = np.concatenate([anchor, positive, negative], axis=1)\n",
    "y_dummy = np.zeros((X_triplet.shape[0],))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef0f0a7-ec07-4fba-a1bb-0c03675d0e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:216: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/15\n",
      "\u001b[1m278/278\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9178\n",
      "Epoch 2/15\n",
      "\u001b[1m278/278\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4037\n",
      "Epoch 3/15\n",
      "\u001b[1m278/278\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2130\n",
      "Epoch 4/15\n",
      "\u001b[1m278/278\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2061\n",
      "Epoch 5/15\n",
      "\u001b[1m278/278\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1283\n",
      "Epoch 6/15\n",
      "\u001b[1m278/278\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0874\n",
      "Epoch 7/15\n",
      "\u001b[1m278/278\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1018\n",
      "Epoch 8/15\n",
      "\u001b[1m278/278\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1807\n",
      "Epoch 9/15\n",
      "\u001b[1m278/278\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0904\n",
      "Epoch 10/15\n",
      "\u001b[1m278/278\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0742\n",
      "Epoch 11/15\n",
      "\u001b[1m278/278\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0703\n",
      "Epoch 12/15\n",
      "\u001b[1m278/278\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0534\n",
      "Epoch 13/15\n",
      "\u001b[1m278/278\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0638\n",
      "Epoch 14/15\n",
      "\u001b[1m278/278\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0612\n",
      "Epoch 15/15\n",
      "\u001b[1m278/278\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x240c0e2a8a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Build Triplet Network ===\n",
    "def build_base_network(input_shape):\n",
    "    inp = Input(shape=(input_shape,))\n",
    "    x = Dense(128, activation='relu')(inp)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation='linear')(x)\n",
    "    return Model(inp, x)\n",
    "\n",
    "input_shape = anchor.shape[1]\n",
    "base_network = build_base_network(input_shape)\n",
    "\n",
    "anchor_input = Input(shape=(input_shape,), name='anchor_input')\n",
    "positive_input = Input(shape=(input_shape,), name='positive_input')\n",
    "negative_input = Input(shape=(input_shape,), name='negative_input')\n",
    "\n",
    "encoded_anchor = base_network(anchor_input)\n",
    "encoded_positive = base_network(positive_input)\n",
    "encoded_negative = base_network(negative_input)\n",
    "\n",
    "merged_output = Lambda(lambda x: K.concatenate(x, axis=1))([encoded_anchor, encoded_positive, encoded_negative])\n",
    "triplet_model = Model(inputs=[anchor_input, positive_input, negative_input], outputs=merged_output)\n",
    "\n",
    "triplet_model.compile(loss=triplet_loss(margin=1.0), optimizer=Adam(0.001))\n",
    "triplet_model.fit([anchor, positive, negative], y_dummy, batch_size=64, epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcc085f9-adf8-4886-9322-c9072d14548b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7199/7199\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 538us/step\n",
      "\u001b[1m556/556\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step\n",
      "\n",
      "[Ensemble Detection Evaluation]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.96      0.95      0.96    230339\n",
      "    SPOOFING       0.46      0.54      0.50     17791\n",
      "\n",
      "    accuracy                           0.92    248130\n",
      "   macro avg       0.71      0.75      0.73    248130\n",
      "weighted avg       0.93      0.92      0.92    248130\n",
      "\n",
      "ROC-AUC: 0.7466822027453047\n"
     ]
    }
   ],
   "source": [
    "# === Embedding dan Deteksi Anomali ===\n",
    "encoder_model = base_network\n",
    "embedding_benign = encoder_model.predict(scaler.transform(benign_df[valid_cols]))\n",
    "embedding_zero = encoder_model.predict(scaler.transform(zero_df[valid_cols]))\n",
    "\n",
    "# Isolation Forest\n",
    "iso = IsolationForest(contamination=0.05, random_state=42)\n",
    "iso.fit(embedding_benign)\n",
    "iso_pred = [1 if p == -1 else 0 for p in np.concatenate([iso.predict(embedding_benign), iso.predict(embedding_zero)])]\n",
    "\n",
    "# One-Class SVM\n",
    "svm = OneClassSVM(kernel='rbf', gamma='auto')\n",
    "svm.fit(embedding_benign)\n",
    "svm_pred = [1 if p == -1 else 0 for p in np.concatenate([svm.predict(embedding_benign), svm.predict(embedding_zero)])]\n",
    "\n",
    "# Mahalanobis Distance\n",
    "mean_vec = np.mean(embedding_benign, axis=0)\n",
    "cov_inv = np.linalg.pinv(np.cov(embedding_benign, rowvar=False))\n",
    "d_mahal_benign = [distance.mahalanobis(x, mean_vec, cov_inv) for x in embedding_benign]\n",
    "d_mahal_zero = [distance.mahalanobis(x, mean_vec, cov_inv) for x in embedding_zero]\n",
    "thresh = np.percentile(d_mahal_benign, 95)\n",
    "mahal_pred = [1 if d > thresh else 0 for d in d_mahal_benign + d_mahal_zero]\n",
    "\n",
    "# Ensemble\n",
    "ensemble_pred = [1 if (s == 1 and m == 1) else 0 for s, m in zip(svm_pred, mahal_pred)]\n",
    "y_true = [0] * len(embedding_benign) + [1] * len(embedding_zero)\n",
    "\n",
    "print(\"\\n[Ensemble Detection Evaluation]\")\n",
    "print(classification_report(y_true, ensemble_pred, target_names=['Benign', zero_attack_label]))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_true, ensemble_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbf46a2-ed09-438c-8515-9bdd638bf914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5146a17e-f309-45ba-ae33-1b569d694933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrastive Learning + Zero-Day Detection for IoMT IDS (Triplet Loss for Better Embedding)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from scipy.spatial import distance\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# === Load Dataset ===\n",
    "def load_dataset_from_structure(root_path):\n",
    "    data = []\n",
    "    for file in root_path.glob(\"**/*.csv\"):\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            if df.empty: continue\n",
    "            category = file.parent.parent.name\n",
    "            attack = file.parent.name\n",
    "            label_class = 'Benign' if category.upper() == 'BENIGN' else 'Attack'\n",
    "            df['category'] = category\n",
    "            df['attack'] = attack\n",
    "            df['class'] = label_class\n",
    "            data.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to read file {file}: {e}\")\n",
    "    return pd.concat(data, ignore_index=True) if data else pd.DataFrame()\n",
    "\n",
    "train_root = Path('../../../Data/CICIoMT2024/train')\n",
    "test_root = Path('../../../Data/CICIoMT2024/test')\n",
    "\n",
    "train_df = load_dataset_from_structure(train_root)\n",
    "test_df = load_dataset_from_structure(test_root)\n",
    "\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b666a35-10bc-44a9-b2a9-eda59d5a1f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attack\n",
       "DDOS UDP              1998026\n",
       "DDOS ICMP             1887175\n",
       "DDOS TCP               987063\n",
       "DDOS SYN               974359\n",
       "DOS UDP                704503\n",
       "DOS SYN                540498\n",
       "DOS ICMP               514724\n",
       "DOS TCP                462480\n",
       "BENIGN                 230339\n",
       "DDOS CONNECT FLOOD     214952\n",
       "PORT SCAN              106603\n",
       "DOS PUBLISH FLOOD       52881\n",
       "DDOS PUBLISH FLOOD      36039\n",
       "OS SCAN                 20666\n",
       "SPOOFING                17791\n",
       "DOS CONNECT FLOOD       15904\n",
       "MALFORMED DATA           6877\n",
       "RECON VULSCAN            3207\n",
       "PING SWEEP                926\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['attack'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de612f0-3e4a-4fa0-b8d2-6d51b56f210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Triplet Loss Function ===\n",
    "def triplet_loss(margin=1.0):\n",
    "    def loss(y_true, y_pred):\n",
    "        anchor, positive, negative = y_pred[:, :32], y_pred[:, 32:64], y_pred[:, 64:]\n",
    "        pos_dist = K.sum(K.square(anchor - positive), axis=1)\n",
    "        neg_dist = K.sum(K.square(anchor - negative), axis=1)\n",
    "        return K.mean(K.maximum(pos_dist - neg_dist + margin, 0.0))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e23522e2-dc3d-4831-bfb7-cdcfb14caff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Unique attack values: ['BENIGN' 'DDOS ICMP' 'DDOS SYN' 'DDOS TCP' 'DDOS UDP' 'DOS ICMP'\n",
      " 'DOS SYN' 'DOS TCP' 'DOS UDP' 'DDOS CONNECT FLOOD' 'DDOS PUBLISH FLOOD'\n",
      " 'DOS CONNECT FLOOD' 'DOS PUBLISH FLOOD' 'MALFORMED DATA' 'OS SCAN'\n",
      " 'PING SWEEP' 'PORT SCAN' 'RECON VULSCAN' 'SPOOFING']\n",
      "[INFO] valid_cols: 45 features\n",
      "[INFO] triplet_benign shape: (230339, 45)\n",
      "[INFO] triplet_attack shape: (230339, 45)\n",
      "[INFO] triplet_zero shape: (230339, 45)\n"
     ]
    }
   ],
   "source": [
    "# === Prepare Data ===\n",
    "df['attack'] = df['attack'].str.upper().str.strip()\n",
    "df['class'] = df['class'].str.upper().str.strip()\n",
    "\n",
    "print(\"ğŸ” Unique attack values:\", df['attack'].unique())\n",
    "\n",
    "zero_attack_label = 'DDOS UDP'  # Sebelumnya 'DDoS UDP', tidak cocok dengan data\n",
    "benign_df = df[df['class'] == 'BENIGN'].copy()\n",
    "zero_df = df[df['attack'] == zero_attack_label].copy()\n",
    "attack_df = df[(df['class'] == 'ATTACK') & (df['attack'] != zero_attack_label)].copy()\n",
    "\n",
    "triplet_size = min(len(benign_df), len(zero_df), len(attack_df))\n",
    "if triplet_size == 0:\n",
    "    raise ValueError(\"Triplet datasets are empty. Periksa kembali label 'BENIGN', 'DDoS UDP', atau struktur data.\")\n",
    "\n",
    "triplet_benign = benign_df.sample(n=triplet_size, random_state=42)\n",
    "triplet_attack = attack_df.sample(n=triplet_size, random_state=42)\n",
    "triplet_zero = zero_df.sample(n=triplet_size, random_state=42)\n",
    "\n",
    "feature_cols = df.select_dtypes(include='number').columns.tolist()\n",
    "triplet_benign = triplet_benign.dropna(subset=feature_cols)\n",
    "triplet_attack = triplet_attack.dropna(subset=feature_cols)\n",
    "triplet_zero = triplet_zero.dropna(subset=feature_cols)\n",
    "\n",
    "valid_cols = list(set(feature_cols).intersection(\n",
    "    triplet_benign.columns, triplet_attack.columns, triplet_zero.columns\n",
    "))\n",
    "\n",
    "print(f\"[INFO] valid_cols: {len(valid_cols)} features\")\n",
    "print(f\"[INFO] triplet_benign shape: {triplet_benign[valid_cols].shape}\")\n",
    "print(f\"[INFO] triplet_attack shape: {triplet_attack[valid_cols].shape}\")\n",
    "print(f\"[INFO] triplet_zero shape: {triplet_zero[valid_cols].shape}\")\n",
    "\n",
    "if not valid_cols:\n",
    "    raise ValueError(\"Tidak ada fitur numerik yang cocok di antara triplet datasets. Periksa kembali struktur datanya.\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[valid_cols])\n",
    "\n",
    "anchor = scaler.transform(triplet_benign[valid_cols])\n",
    "positive = scaler.transform(triplet_attack[valid_cols])\n",
    "negative = scaler.transform(triplet_zero[valid_cols])\n",
    "\n",
    "X_triplet = np.concatenate([anchor, positive, negative], axis=1)\n",
    "y_dummy = np.zeros((X_triplet.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc60e0cd-817f-4a4e-9712-70eb5d277568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:216: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/15\n",
      "\u001b[1m3600/3600\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.8214\n",
      "Epoch 2/15\n",
      "\u001b[1m3600/3600\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.1253\n",
      "Epoch 3/15\n",
      "\u001b[1m3600/3600\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.0954\n",
      "Epoch 4/15\n",
      "\u001b[1m3600/3600\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0830\n",
      "Epoch 5/15\n",
      "\u001b[1m3600/3600\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0817\n",
      "Epoch 6/15\n",
      "\u001b[1m3600/3600\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.0772\n",
      "Epoch 7/15\n",
      "\u001b[1m3600/3600\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0758\n",
      "Epoch 8/15\n",
      "\u001b[1m3600/3600\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0762\n",
      "Epoch 9/15\n",
      "\u001b[1m3600/3600\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0756\n",
      "Epoch 10/15\n",
      "\u001b[1m3600/3600\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0772\n",
      "Epoch 11/15\n",
      "\u001b[1m3600/3600\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0741\n",
      "Epoch 12/15\n",
      "\u001b[1m3600/3600\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.0737\n",
      "Epoch 13/15\n",
      "\u001b[1m3600/3600\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.0764\n",
      "Epoch 14/15\n",
      "\u001b[1m3600/3600\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.0745\n",
      "Epoch 15/15\n",
      "\u001b[1m3600/3600\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.0732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2104fdd33b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Build Triplet Network ===\n",
    "def build_base_network(input_shape):\n",
    "    inp = Input(shape=(input_shape,))\n",
    "    x = Dense(128, activation='relu')(inp)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation='linear')(x)\n",
    "    return Model(inp, x)\n",
    "\n",
    "input_shape = anchor.shape[1]\n",
    "base_network = build_base_network(input_shape)\n",
    "\n",
    "anchor_input = Input(shape=(input_shape,), name='anchor_input')\n",
    "positive_input = Input(shape=(input_shape,), name='positive_input')\n",
    "negative_input = Input(shape=(input_shape,), name='negative_input')\n",
    "\n",
    "encoded_anchor = base_network(anchor_input)\n",
    "encoded_positive = base_network(positive_input)\n",
    "encoded_negative = base_network(negative_input)\n",
    "\n",
    "merged_output = Lambda(lambda x: K.concatenate(x, axis=1))([encoded_anchor, encoded_positive, encoded_negative])\n",
    "triplet_model = Model(inputs=[anchor_input, positive_input, negative_input], outputs=merged_output)\n",
    "\n",
    "triplet_model.compile(loss=triplet_loss(margin=1.0), optimizer=Adam(0.001))\n",
    "triplet_model.fit([anchor, positive, negative], y_dummy, batch_size=64, epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "addd1215-d4f4-4b5b-b3af-8e456a2a8c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7199/7199\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 714us/step\n",
      "\u001b[1m62439/62439\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 758us/step\n"
     ]
    }
   ],
   "source": [
    "# === Embedding dan Deteksi Anomali ===\n",
    "encoder_model = base_network\n",
    "embedding_benign = encoder_model.predict(scaler.transform(benign_df[valid_cols]))\n",
    "embedding_zero = encoder_model.predict(scaler.transform(zero_df[valid_cols]))\n",
    "\n",
    "# Isolation Forest\n",
    "iso = IsolationForest(contamination=0.05, random_state=42)\n",
    "iso.fit(embedding_benign)\n",
    "iso_pred = [1 if p == -1 else 0 for p in np.concatenate([iso.predict(embedding_benign), iso.predict(embedding_zero)])]\n",
    "\n",
    "# One-Class SVM\n",
    "svm = OneClassSVM(kernel='rbf', gamma='auto')\n",
    "svm.fit(embedding_benign)\n",
    "svm_pred = [1 if p == -1 else 0 for p in np.concatenate([svm.predict(embedding_benign), svm.predict(embedding_zero)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8563bef-f464-4dc9-8dcc-7e424b7085e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahalanobis Distance\n",
    "mean_vec = np.mean(embedding_benign, axis=0)\n",
    "cov_inv = np.linalg.pinv(np.cov(embedding_benign, rowvar=False))\n",
    "d_mahal_benign = [distance.mahalanobis(x, mean_vec, cov_inv) for x in embedding_benign]\n",
    "d_mahal_zero = [distance.mahalanobis(x, mean_vec, cov_inv) for x in embedding_zero]\n",
    "thresh = np.percentile(d_mahal_benign, 95)\n",
    "mahal_pred = [1 if d > thresh else 0 for d in d_mahal_benign + d_mahal_zero]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3604f723-aedb-46f2-b4ca-81cf81082d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Ensemble Detection Evaluation]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       1.00      0.95      0.97    230339\n",
      "    DDOS UDP       0.99      1.00      1.00   1998026\n",
      "\n",
      "    accuracy                           0.99   2228365\n",
      "   macro avg       1.00      0.98      0.99   2228365\n",
      "weighted avg       0.99      0.99      0.99   2228365\n",
      "\n",
      "ROC-AUC: 0.9756061082811225\n"
     ]
    }
   ],
   "source": [
    "# Ensemble\n",
    "ensemble_pred = [1 if (s == 1 and m == 1) else 0 for s, m in zip(svm_pred, mahal_pred)]\n",
    "y_true = [0] * len(embedding_benign) + [1] * len(embedding_zero)\n",
    "\n",
    "print(\"\\n[Ensemble Detection Evaluation]\")\n",
    "print(classification_report(y_true, ensemble_pred, target_names=['Benign', zero_attack_label]))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_true, ensemble_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd561b10-d753-481b-80c8-38e2cf0155b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
